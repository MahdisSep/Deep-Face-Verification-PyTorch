# -*- coding: utf-8 -*-
"""ML-Vision-Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hOc5gNsHauBy5B5oKBUfFwJw8BzfDQdZ
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import torchvision
import torchvision.datasets as dset
import torchvision.transforms as transforms
from torch.utils.data import DataLoader,Dataset
import matplotlib.pyplot as plt
import torchvision.utils
import numpy as np
import random
from PIL import Image
import torch
from torch.autograd import Variable
import PIL.ImageOps
import torch.nn as nn
from torch import optim
import torch.nn.functional as F

import kagglehub

vggface2_path = kagglehub.dataset_download('hearfool/vggface2')
print(vggface2_path)

def imshow(img,text=None,should_save=False):
    npimg = img.numpy()
    plt.axis("off")
    if text:
        plt.text(75, 8, text, style='italic',fontweight='bold',
            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

def show_plot(iteration,loss):
    plt.plot(iteration,loss)
    plt.show()

import os
class Config():
    # مسیر اصلی دیتاست VGGFace2
    base_dir = "/root/.cache/kagglehub/datasets/hearfool/vggface2/versions/1"

    # مسیر داده‌های آموزشی و آزمایشی
    training_dir = os.path.join(base_dir, "train")
    testing_dir = os.path.join(base_dir, "val")

    # تنظیمات آموزش
    train_batch_size = 64
    train_number_epochs = 500
    train_subset_size = 500  # Subset size for training
    val_subset_size = 500    # Subset size for validation

class SiameseNetworkDataset(Dataset):
    def __init__(self, image_paths, transform=None, should_invert=True):
        self.image_paths = image_paths
        self.transform = transform
        self.should_invert = should_invert

    def __getitem__(self, index):
        img0_path, img0_label = random.choice(self.image_paths)
        should_get_same_class = random.randint(0, 1)

        if should_get_same_class:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] == img0_label])
        else:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] != img0_label])

        img0 = Image.open(img0_path).convert("L")
        img1 = Image.open(img1_path).convert("L")

        if self.should_invert:
            img0 = PIL.ImageOps.invert(img0)
            img1 = PIL.ImageOps.invert(img1)

        if self.transform:
            img0 = self.transform(img0)
            img1 = self.transform(img1)

        return img0, img1, torch.from_numpy(np.array([int(img1_label != img0_label)], dtype=np.float32))

    def __len__(self):
        return len(self.image_paths)

from torch.utils.data import DataLoader, Dataset, Subset
import random
import os
folder_dataset_train = dset.ImageFolder(root=Config.training_dir)
train_subset_indices = random.sample(range(len(folder_dataset_train.imgs)), Config.train_subset_size)
train_subset_paths = [folder_dataset_train.imgs[i] for i in train_subset_indices]

siamese_dataset_train = SiameseNetworkDataset(
    image_paths=train_subset_paths,
    transform=transforms.Compose([transforms.Resize((100, 100)), transforms.ToTensor()]),
    should_invert=False
)

train_dataloader = DataLoader(
    siamese_dataset_train, shuffle=True, num_workers=4, batch_size=Config.train_batch_size
)

dataiter = iter(train_dataloader)


example_batch = next(dataiter)
concatenated = torch.cat((example_batch[0],example_batch[1]),0)
imshow(torchvision.utils.make_grid(concatenated))
print(example_batch[2].numpy())

class SiameseNetwork(nn.Module):
    def __init__(self):
        super(SiameseNetwork, self).__init__()
        self.cnn1 = nn.Sequential(
            nn.ReflectionPad2d(1),
            nn.Conv2d(1, 4, kernel_size=3),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(4),

            nn.ReflectionPad2d(1),
            nn.Conv2d(4, 8, kernel_size=3),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(8),


            nn.ReflectionPad2d(1),
            nn.Conv2d(8, 8, kernel_size=3),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(8),


        )

        self.fc1 = nn.Sequential(
            nn.Linear(8*100*100, 500),
            nn.ReLU(inplace=True),

            nn.Linear(500, 500),
            nn.ReLU(inplace=True),

            nn.Linear(500, 5))

    def forward_once(self, x):
        output = self.cnn1(x)
        output = output.view(output.size()[0], -1)
        output = self.fc1(output)
        return output

    def forward(self, input1, input2):
        output1 = self.forward_once(input1)
        output2 = self.forward_once(input2)
        return output1, output2

class ContrastiveLoss(torch.nn.Module):
    """
    Contrastive loss function.
    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf
    """

    def __init__(self, margin=2.0):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin

    def forward(self, output1, output2, label):
        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +
                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))


        return loss_contrastive

net = SiameseNetwork().cuda()
criterion = ContrastiveLoss()
optimizer = optim.Adam(net.parameters(),lr = 0.0005 )

counter = []
loss_history = []
iteration_number= 0

for epoch in range(Config.train_number_epochs):
    for i, data in enumerate(train_dataloader, 0):
        img0, img1, label = data
        img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()
        optimizer.zero_grad()
        output1, output2 = net(img0, img1)
        loss_contrastive = criterion(output1, output2, label)
        loss_contrastive.backward()
        optimizer.step()
        if i % 10 == 0:
            print(f"Epoch {epoch}, Loss: {loss_contrastive.item()}")

"""#normal test"""

folder_dataset_val = dset.ImageFolder(root=Config.testing_dir)
val_subset_indices = random.sample(range(len(folder_dataset_val.imgs)), Config.val_subset_size)
val_subset_paths = [folder_dataset_val.imgs[i] for i in val_subset_indices]

siamese_dataset_val = SiameseNetworkDataset(
    image_paths=val_subset_paths,
    transform=transforms.Compose([transforms.Resize((100, 100)), transforms.ToTensor()]),
    should_invert=False
)

val_dataloader = DataLoader(siamese_dataset_val, num_workers=4, batch_size=1, shuffle=True)

# Sample validation with plots
val_dataiter = iter(val_dataloader)
x0, _, _ = next(val_dataiter)
correct = 0
total = 0
for i, data in enumerate(val_dataloader):
    x0, x1, label = data
    output1, output2 = net(x0.cuda(), x1.cuda())
    euclidean_distance = F.pairwise_distance(output1, output2)
    prediction = (euclidean_distance > 1.0).float()  # Threshold can be adjusted

    # Accuracy calculation
    correct += (prediction.cpu() == label).sum().item()
    total += label.size(0)

    # Plot the images
    fig, axs = plt.subplots(1, 2, figsize=(5, 5))
    axs[0].imshow(x0.squeeze().cpu().numpy(), cmap='gray')
    axs[0].axis('off')
    axs[0].set_title('Image 1')

    axs[1].imshow(x1.squeeze().cpu().numpy(), cmap='gray')
    axs[1].axis('off')
    axs[1].set_title('Image 2')

    plt.suptitle(f'Dissimilarity: {euclidean_distance.item():.2f}')
    plt.show()

# Print overall accuracy
accuracy = correct / total * 100
print(f'Overall Accuracy: {accuracy:.2f}%')

"""#data augmentation 71%"""

import torchvision.datasets as dset
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import random
import os
from PIL import Image
import numpy as np
import torch
import PIL.ImageOps
import torch.nn as nn
from torch import optim
import torch.nn.functional as F
import matplotlib.pyplot as plt

# Config class with dataset paths
class Config:
    base_dir = "/root/.cache/kagglehub/datasets/hearfool/vggface2/versions/1"
    training_dir = os.path.join(base_dir, "train")
    validation_dir = os.path.join(base_dir, "val")
    train_batch_size = 64
    train_number_epochs = 100
    train_subset_size = 500  # Increased subset size for training
    val_subset_size = 100    # Subset size for validation


# Data augmentation and preprocessing
transform = transforms.Compose([
    transforms.Resize((100, 100)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor()
])

# Dataset class
class SiameseNetworkDataset(Dataset):
    def __init__(self, image_paths, transform=None, should_invert=True):
        self.image_paths = image_paths
        self.transform = transform
        self.should_invert = should_invert

    def __getitem__(self, index):
        img0_path, img0_label = random.choice(self.image_paths)
        should_get_same_class = random.randint(0, 1)

        if should_get_same_class:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] == img0_label])
        else:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] != img0_label])

        img0 = Image.open(img0_path).convert("L")
        img1 = Image.open(img1_path).convert("L")

        if self.should_invert:
            img0 = PIL.ImageOps.invert(img0)
            img1 = PIL.ImageOps.invert(img1)

        if self.transform:
            img0 = self.transform(img0)
            img1 = self.transform(img1)

        return img0, img1, torch.from_numpy(np.array([int(img1_label != img0_label)], dtype=np.float32))

    def __len__(self):
        return len(self.image_paths)


# Load dataset and create subsets
def load_dataset(directory, subset_size):
    folder_dataset = dset.ImageFolder(root=directory)
    subset_indices = random.sample(range(len(folder_dataset.imgs)), subset_size)
    subset_paths = [folder_dataset.imgs[i] for i in subset_indices]
    return SiameseNetworkDataset(image_paths=subset_paths, transform=transform, should_invert=False)

siamese_dataset_train = load_dataset(Config.training_dir, Config.train_subset_size)
train_dataloader = DataLoader(siamese_dataset_train, shuffle=True, num_workers=4, batch_size=Config.train_batch_size)

# Define Siamese Network
class SiameseNetwork(nn.Module):
    def __init__(self):
        super(SiameseNetwork, self).__init__()
        self.cnn1 = nn.Sequential(
            nn.ReflectionPad2d(1), nn.Conv2d(1, 4, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(4),
            nn.ReflectionPad2d(1), nn.Conv2d(4, 8, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(8),
            nn.ReflectionPad2d(1), nn.Conv2d(8, 8, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(8)
        )
        self.fc1 = nn.Sequential(
            nn.Linear(8 * 100 * 100, 500), nn.ReLU(inplace=True),
            nn.Linear(500, 500), nn.ReLU(inplace=True),
            nn.Linear(500, 128)  # Embedding dimension
        )

    def forward_once(self, x):
        output = self.cnn1(x)
        output = output.view(output.size()[0], -1)
        output = self.fc1(output)
        return output

    def forward(self, input1, input2):
        output1 = self.forward_once(input1)
        output2 = self.forward_once(input2)
        return output1, output2


# Contrastive Loss
class ContrastiveLoss(torch.nn.Module):
    def __init__(self, margin=2.0):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin

    def forward(self, output1, output2, label):
        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)
        loss_contrastive = torch.mean(
            (1 - label) * torch.pow(euclidean_distance, 2) +
            label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)
        )
        return loss_contrastive


# Model training function
def train_model(net, train_loader, criterion, optimizer, epochs):
    for epoch in range(epochs):
        for i, data in enumerate(train_loader, 0):
            img0, img1, label = data
            img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()
            optimizer.zero_grad()
            output1, output2 = net(img0, img1)
            loss_contrastive = criterion(output1, output2, label)
            loss_contrastive.backward()
            optimizer.step()

            if i % 10 == 0:
                print(f"Epoch {epoch}, Loss: {loss_contrastive.item()}")


# Model training
net = SiameseNetwork().cuda()
criterion = ContrastiveLoss()
optimizer = optim.Adam(net.parameters(), lr=0.0005)
train_model(net, train_dataloader, criterion, optimizer, Config.train_number_epochs)

# Validation with subset
siamese_dataset_val = load_dataset(Config.validation_dir, Config.val_subset_size)
val_dataloader = DataLoader(siamese_dataset_val, num_workers=4, batch_size=1, shuffle=True)

# Validation function
def validate_model(net, val_loader):
    correct, total = 0, 0
    for data in val_loader:
        x0, x1, label = data
        output1, output2 = net(x0.cuda(), x1.cuda())
        euclidean_distance = F.pairwise_distance(output1, output2)
        prediction = (euclidean_distance > 1.0).float()

        correct += (prediction.cpu() == label).sum().item()
        total += label.size(0)

        fig, axs = plt.subplots(1, 2, figsize=(5, 5))
        axs[0].imshow(x0.squeeze().cpu().numpy(), cmap='gray')
        axs[0].axis('off')
        axs[0].set_title('Image 1')

        axs[1].imshow(x1.squeeze().cpu().numpy(), cmap='gray')
        axs[1].axis('off')
        axs[1].set_title('Image 2')

        plt.suptitle(f'Dissimilarity: {euclidean_distance.item():.2f}')
        plt.show()

    accuracy = correct / total * 100
    print(f'Overall Accuracy: {accuracy:.2f}%')


# Run validation
validate_model(net, val_dataloader)

"""# increase epochs to 300 -> 59%"""

import torchvision.datasets as dset
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import random
import os
from PIL import Image
import numpy as np
import torch
import PIL.ImageOps
import torch.nn as nn
from torch import optim
import torch.nn.functional as F
import matplotlib.pyplot as plt

# Config class with dataset paths
class Config:
    base_dir = "/root/.cache/kagglehub/datasets/hearfool/vggface2/versions/1"
    training_dir = os.path.join(base_dir, "train")
    validation_dir = os.path.join(base_dir, "val")
    train_batch_size = 64
    train_number_epochs = 300
    train_subset_size = 500  # Increased subset size for training
    val_subset_size = 100    # Subset size for validation


# Data augmentation and preprocessing
transform = transforms.Compose([
    transforms.Resize((100, 100)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor()
])

# Dataset class
class SiameseNetworkDataset(Dataset):
    def __init__(self, image_paths, transform=None, should_invert=True):
        self.image_paths = image_paths
        self.transform = transform
        self.should_invert = should_invert

    def __getitem__(self, index):
        img0_path, img0_label = random.choice(self.image_paths)
        should_get_same_class = random.randint(0, 1)

        if should_get_same_class:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] == img0_label])
        else:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] != img0_label])

        img0 = Image.open(img0_path).convert("L")
        img1 = Image.open(img1_path).convert("L")

        if self.should_invert:
            img0 = PIL.ImageOps.invert(img0)
            img1 = PIL.ImageOps.invert(img1)

        if self.transform:
            img0 = self.transform(img0)
            img1 = self.transform(img1)

        return img0, img1, torch.from_numpy(np.array([int(img1_label != img0_label)], dtype=np.float32))

    def __len__(self):
        return len(self.image_paths)


# Load dataset and create subsets
def load_dataset(directory, subset_size):
    folder_dataset = dset.ImageFolder(root=directory)
    subset_indices = random.sample(range(len(folder_dataset.imgs)), subset_size)
    subset_paths = [folder_dataset.imgs[i] for i in subset_indices]
    return SiameseNetworkDataset(image_paths=subset_paths, transform=transform, should_invert=False)

siamese_dataset_train = load_dataset(Config.training_dir, Config.train_subset_size)
train_dataloader = DataLoader(siamese_dataset_train, shuffle=True, num_workers=4, batch_size=Config.train_batch_size)

# Define Siamese Network
class SiameseNetwork(nn.Module):
    def __init__(self):
        super(SiameseNetwork, self).__init__()
        self.cnn1 = nn.Sequential(
            nn.ReflectionPad2d(1), nn.Conv2d(1, 4, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(4),
            nn.ReflectionPad2d(1), nn.Conv2d(4, 8, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(8),
            nn.ReflectionPad2d(1), nn.Conv2d(8, 8, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(8)
        )
        self.fc1 = nn.Sequential(
            nn.Linear(8 * 100 * 100, 500), nn.ReLU(inplace=True),
            nn.Linear(500, 500), nn.ReLU(inplace=True),
            nn.Linear(500, 128)  # Embedding dimension
        )

    def forward_once(self, x):
        output = self.cnn1(x)
        output = output.view(output.size()[0], -1)
        output = self.fc1(output)
        return output

    def forward(self, input1, input2):
        output1 = self.forward_once(input1)
        output2 = self.forward_once(input2)
        return output1, output2


# Contrastive Loss
class ContrastiveLoss(torch.nn.Module):
    def __init__(self, margin=2.0):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin

    def forward(self, output1, output2, label):
        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)
        loss_contrastive = torch.mean(
            (1 - label) * torch.pow(euclidean_distance, 2) +
            label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)
        )
        return loss_contrastive


# Model training function
def train_model(net, train_loader, criterion, optimizer, epochs):
    for epoch in range(epochs):
        for i, data in enumerate(train_loader, 0):
            img0, img1, label = data
            img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()
            optimizer.zero_grad()
            output1, output2 = net(img0, img1)
            loss_contrastive = criterion(output1, output2, label)
            loss_contrastive.backward()
            optimizer.step()

            if i % 10 == 0:
                print(f"Epoch {epoch}, Loss: {loss_contrastive.item()}")


# Model training
net = SiameseNetwork().cuda()
criterion = ContrastiveLoss()
optimizer = optim.Adam(net.parameters(), lr=0.0005)
train_model(net, train_dataloader, criterion, optimizer, Config.train_number_epochs)

# Validation with subset
siamese_dataset_val = load_dataset(Config.validation_dir, Config.val_subset_size)
val_dataloader = DataLoader(siamese_dataset_val, num_workers=4, batch_size=1, shuffle=True)

# Validation function
def validate_model(net, val_loader):
    correct, total = 0, 0
    for data in val_loader:
        x0, x1, label = data
        output1, output2 = net(x0.cuda(), x1.cuda())
        euclidean_distance = F.pairwise_distance(output1, output2)
        prediction = (euclidean_distance > 1.0).float()

        correct += (prediction.cpu() == label).sum().item()
        total += label.size(0)

        fig, axs = plt.subplots(1, 2, figsize=(5, 5))
        axs[0].imshow(x0.squeeze().cpu().numpy(), cmap='gray')
        axs[0].axis('off')
        axs[0].set_title('Image 1')

        axs[1].imshow(x1.squeeze().cpu().numpy(), cmap='gray')
        axs[1].axis('off')
        axs[1].set_title('Image 2')

        plt.suptitle(f'Dissimilarity: {euclidean_distance.item():.2f}')
        plt.show()

    accuracy = correct / total * 100
    print(f'Overall Accuracy: {accuracy:.2f}%')


# Run validation
validate_model(net, val_dataloader)

"""#increase epochs to 150 - > 60%"""

import torchvision.datasets as dset
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import random
import os
from PIL import Image
import numpy as np
import torch
import PIL.ImageOps
import torch.nn as nn
from torch import optim
import torch.nn.functional as F
import matplotlib.pyplot as plt

# Config class with dataset paths
class Config:
    base_dir = "/root/.cache/kagglehub/datasets/hearfool/vggface2/versions/1"
    training_dir = os.path.join(base_dir, "train")
    validation_dir = os.path.join(base_dir, "val")
    train_batch_size = 64
    train_number_epochs = 150  # Increased epochs
    train_subset_size = 500
    val_subset_size = 100

# Data augmentation and preprocessing
transform = transforms.Compose([
    transforms.Resize((100, 100)),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Enhanced augmentation
    transforms.RandomRotation(15),
    transforms.ToTensor()
])

# Dataset class
class SiameseNetworkDataset(Dataset):
    def __init__(self, image_paths, transform=None, should_invert=True):
        self.image_paths = image_paths
        self.transform = transform
        self.should_invert = should_invert

    def __getitem__(self, index):
        img0_path, img0_label = random.choice(self.image_paths)
        should_get_same_class = random.randint(0, 1)

        if should_get_same_class:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] == img0_label])
        else:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] != img0_label])

        img0 = Image.open(img0_path).convert("L")
        img1 = Image.open(img1_path).convert("L")

        if self.should_invert:
            img0 = PIL.ImageOps.invert(img0)
            img1 = PIL.ImageOps.invert(img1)

        if self.transform:
            img0 = self.transform(img0)
            img1 = self.transform(img1)

        return img0, img1, torch.from_numpy(np.array([int(img1_label != img0_label)], dtype=np.float32))

    def __len__(self):
        return len(self.image_paths)

# Load dataset and create subsets
def load_dataset(directory, subset_size):
    folder_dataset = dset.ImageFolder(root=directory)
    subset_indices = random.sample(range(len(folder_dataset.imgs)), subset_size)
    subset_paths = [folder_dataset.imgs[i] for i in subset_indices]
    return SiameseNetworkDataset(image_paths=subset_paths, transform=transform, should_invert=False)

siamese_dataset_train = load_dataset(Config.training_dir, Config.train_subset_size)
train_dataloader = DataLoader(siamese_dataset_train, shuffle=True, num_workers=4, batch_size=Config.train_batch_size)

# Define Siamese Network with added dropout
class SiameseNetwork(nn.Module):
    def __init__(self):
        super(SiameseNetwork, self).__init__()
        self.cnn1 = nn.Sequential(
            nn.ReflectionPad2d(1), nn.Conv2d(1, 8, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(8),
            nn.ReflectionPad2d(1), nn.Conv2d(8, 16, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(16),
            nn.ReflectionPad2d(1), nn.Conv2d(16, 16, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(16),
            nn.Dropout(0.3)  # Added dropout
        )
        self.fc1 = nn.Sequential(
            nn.Linear(16 * 100 * 100, 512), nn.ReLU(inplace=True), nn.Dropout(0.5),
            nn.Linear(512, 256), nn.ReLU(inplace=True),
            nn.Linear(256, 128)
        )

    def forward_once(self, x):
        output = self.cnn1(x)
        output = output.view(output.size()[0], -1)
        output = self.fc1(output)
        return output

    def forward(self, input1, input2):
        output1 = self.forward_once(input1)
        output2 = self.forward_once(input2)
        return output1, output2

# Contrastive Loss
class ContrastiveLoss(torch.nn.Module):
    def __init__(self, margin=1.0):  # Adjusted margin
        super(ContrastiveLoss, self).__init__()
        self.margin = margin

    def forward(self, output1, output2, label):
        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)
        loss_contrastive = torch.mean(
            (1 - label) * torch.pow(euclidean_distance, 2) +
            label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)
        )
        return loss_contrastive

# Model training function
def train_model(net, train_loader, criterion, optimizer, epochs):
    for epoch in range(epochs):
        net.train()
        total_loss = 0
        for i, data in enumerate(train_loader, 0):
            img0, img1, label = data
            img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()
            optimizer.zero_grad()
            output1, output2 = net(img0, img1)
            loss_contrastive = criterion(output1, output2, label)
            loss_contrastive.backward()
            optimizer.step()
            total_loss += loss_contrastive.item()

        print(f"Epoch {epoch}, Average Loss: {total_loss / len(train_loader):.4f}")

# Model training
net = SiameseNetwork().cuda()
criterion = ContrastiveLoss()
optimizer = optim.Adam(net.parameters(), lr=0.0003, weight_decay=1e-4)  # Adjusted learning rate and added weight decay
train_model(net, train_dataloader, criterion, optimizer, Config.train_number_epochs)

# Validation with subset
siamese_dataset_val = load_dataset(Config.validation_dir, Config.val_subset_size)
val_dataloader = DataLoader(siamese_dataset_val, num_workers=4, batch_size=1, shuffle=True)

# Validation function
def validate_model(net, val_loader):
    net.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for data in val_loader:
            x0, x1, label = data
            output1, output2 = net(x0.cuda(), x1.cuda())
            euclidean_distance = F.pairwise_distance(output1, output2)
            prediction = (euclidean_distance > 0.8).float()  # Adjusted threshold

            correct += (prediction.cpu() == label).sum().item()
            total += label.size(0)

            fig, axs = plt.subplots(1, 2, figsize=(5, 5))
            axs[0].imshow(x0.squeeze().cpu().numpy(), cmap='gray')
            axs[0].axis('off')
            axs[0].set_title('Image 1')

            axs[1].imshow(x1.squeeze().cpu().numpy(), cmap='gray')
            axs[1].axis('off')
            axs[1].set_title('Image 2')

            plt.suptitle(f'Dissimilarity: {euclidean_distance.item():.2f}')
            plt.show()

    accuracy = correct / total * 100
    print(f'Overall Accuracy: {accuracy:.2f}%')

# Run validation
validate_model(net, val_dataloader)

"""#data augmentation + early stopping"""

import torchvision.datasets as dset
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import random
import os
from PIL import Image
import numpy as np
import torch
import PIL.ImageOps
import torch.nn as nn
from torch import optim
import torch.nn.functional as F
import matplotlib.pyplot as plt

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Config class with dataset paths
class Config:
    base_dir = "/root/.cache/kagglehub/datasets/hearfool/vggface2/versions/1"
    training_dir = os.path.join(base_dir, "train")
    validation_dir = os.path.join(base_dir, "val")
    train_batch_size = 64
    train_number_epochs = 100
    train_subset_size = 500  # Increased subset size for training
    val_subset_size = 100    # Subset size for validation
    patience = 10            # Early stopping patience

# Data augmentation and preprocessing
transform = transforms.Compose([
    transforms.Resize((100, 100)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor()
])

# Dataset class
class SiameseNetworkDataset(Dataset):
    def __init__(self, image_paths, transform=None, should_invert=True):
        self.image_paths = image_paths
        self.transform = transform
        self.should_invert = should_invert

    def __getitem__(self, index):
        img0_path, img0_label = random.choice(self.image_paths)
        should_get_same_class = random.randint(0, 1)

        if should_get_same_class:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] == img0_label])
        else:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] != img0_label])

        img0 = Image.open(img0_path).convert("L")
        img1 = Image.open(img1_path).convert("L")

        if self.should_invert:
            img0 = PIL.ImageOps.invert(img0)
            img1 = PIL.ImageOps.invert(img1)

        if self.transform:
            img0 = self.transform(img0)
            img1 = self.transform(img1)

        return img0, img1, torch.from_numpy(np.array([int(img1_label != img0_label)], dtype=np.float32))

    def __len__(self):
        return len(self.image_paths)

# Load dataset and create subsets
def load_dataset(directory, subset_size):
    folder_dataset = dset.ImageFolder(root=directory)
    subset_indices = random.sample(range(len(folder_dataset.imgs)), subset_size)
    subset_paths = [folder_dataset.imgs[i] for i in subset_indices]
    return SiameseNetworkDataset(image_paths=subset_paths, transform=transform, should_invert=False)

siamese_dataset_train = load_dataset(Config.training_dir, Config.train_subset_size)
train_dataloader = DataLoader(siamese_dataset_train, shuffle=True, num_workers=4, batch_size=Config.train_batch_size)

# Define Siamese Network
class SiameseNetwork(nn.Module):
    def __init__(self):
        super(SiameseNetwork, self).__init__()
        self.cnn1 = nn.Sequential(
            nn.ReflectionPad2d(1), nn.Conv2d(1, 4, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(4),
            nn.ReflectionPad2d(1), nn.Conv2d(4, 8, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(8),
            nn.ReflectionPad2d(1), nn.Conv2d(8, 8, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(8)
        )
        self.fc1 = nn.Sequential(
            nn.Linear(8 * 100 * 100, 500), nn.ReLU(inplace=True),
            nn.Linear(500, 500), nn.ReLU(inplace=True),
            nn.Linear(500, 128)  # Embedding dimension
        )

    def forward_once(self, x):
        output = self.cnn1(x)
        output = output.view(output.size()[0], -1)
        output = self.fc1(output)
        return output

    def forward(self, input1, input2):
        output1 = self.forward_once(input1)
        output2 = self.forward_once(input2)
        return output1, output2

# Contrastive Loss
class ContrastiveLoss(torch.nn.Module):
    def __init__(self, margin=2.0):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin

    def forward(self, output1, output2, label):
        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)
        loss_contrastive = torch.mean(
            (1 - label) * torch.pow(euclidean_distance, 2) +
            label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)
        )
        return loss_contrastive

# Model training function with accuracy tracking and early stopping
def train_model(net, train_loader, criterion, optimizer, epochs, patience):
    train_accuracy_list = []
    train_loss_list = []
    best_loss = float('inf')
    trigger_times = 0

    for epoch in range(epochs):
        correct, total, epoch_loss = 0, 0, 0.0
        net.train()

        for i, data in enumerate(train_loader, 0):
            img0, img1, label = data
            img0, img1, label = img0.to(device), img1.to(device), label.to(device)
            optimizer.zero_grad()
            output1, output2 = net(img0, img1)
            loss_contrastive = criterion(output1, output2, label)
            loss_contrastive.backward()
            optimizer.step()

            euclidean_distance = F.pairwise_distance(output1, output2)
            prediction = (euclidean_distance > 1.0).float()
            correct += (prediction == label).sum().item()
            total += label.size(0)
            epoch_loss += loss_contrastive.item()

        epoch_accuracy = (correct / total) * 100
        epoch_loss /= len(train_loader)
        train_accuracy_list.append(epoch_accuracy)
        train_loss_list.append(epoch_loss)

        print(f"Epoch {epoch + 1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%")

        # Early stopping
        if epoch_loss < best_loss:
            best_loss = epoch_loss
            trigger_times = 0
        else:
            trigger_times += 1
            if trigger_times >= patience:
                print("Early stopping triggered")
                break

    return train_accuracy_list, train_loss_list

# Validation function with accuracy and loss tracking
def validate_model(net, val_loader, criterion):
    val_accuracy_list = []
    val_loss_list = []

    correct, total, val_loss = 0, 0, 0.0
    net.eval()
    with torch.no_grad():
        for data in val_loader:
            x0, x1, label = data
            x0, x1, label = x0.to(device), x1.to(device), label.to(device)
            output1, output2 = net(x0, x1)

            euclidean_distance = F.pairwise_distance(output1, output2)
            prediction = (euclidean_distance > 1.0).float()
            correct += (prediction == label).sum().item()
            total += label.size(0)

            loss_contrastive = criterion(output1, output2, label)
            val_loss += loss_contrastive.item()

    accuracy = (correct / total) * 100
    val_loss /= len(val_loader)
    val_accuracy_list.append(accuracy)
    val_loss_list.append(val_loss)

    print(f'Validation Accuracy: {accuracy:.2f}%')
    return val_accuracy_list, val_loss_list

# Model training
net = SiameseNetwork().to(device)
criterion = ContrastiveLoss()
optimizer = optim.Adam(net.parameters(), lr=0.0005)

train_accuracy_list, train_loss_list = train_model(net, train_dataloader, criterion, optimizer, Config.train_number_epochs, Config.patience)

# Validation with subset
siamese_dataset_val = load_dataset(Config.validation_dir, Config.val_subset_size)
val_dataloader = DataLoader(siamese_dataset_val, num_workers=4, batch_size=1, shuffle=True)

val_accuracy_list, val_loss_list = validate_model(net, val_dataloader, criterion)

# Plotting Accuracy and Loss over Epochs
plt.figure(figsize=(12, 10))

plt.subplot(2, 2, 1)
plt.plot(train_accuracy_list, label='Training Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy (%)')
plt.title('Training Accuracy Over Epochs')
plt.legend()

plt.subplot(2, 2, 2)
plt.plot(train_loss_list, label='Training Loss', color='red')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.legend()

plt.subplot(2, 2, 3)
plt.plot(val_accuracy_list * len(train_accuracy_list), label='Validation Accuracy', color='green')
plt.xlabel('Epochs')
plt.ylabel('Accuracy (%)')
plt.title('Validation Accuracy Over Epochs')
plt.legend()

plt.subplot(2, 2, 4)
plt.plot(val_loss_list * len(train_loss_list), label='Validation Loss', color='blue')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Validation Loss Over Epochs')
plt.legend()

plt.tight_layout()
plt.show()

import torchvision.datasets as dset
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import random
import os
from PIL import Image
import numpy as np
import torch
import PIL.ImageOps
import torch.nn as nn
from torch import optim
import torch.nn.functional as F
import matplotlib.pyplot as plt

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Config class with dataset paths
class Config:
    base_dir = "/root/.cache/kagglehub/datasets/hearfool/vggface2/versions/1"
    training_dir = os.path.join(base_dir, "train")
    validation_dir = os.path.join(base_dir, "val")
    train_batch_size = 64
    train_number_epochs = 100
    train_subset_size = 500  # Increased subset size for training
    val_subset_size = 100    # Subset size for validation
    patience = 10            # Early stopping patience

# Data augmentation and preprocessing
transform = transforms.Compose([
    transforms.Resize((100, 100)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor()
])

# Dataset class
class SiameseNetworkDataset(Dataset):
    def __init__(self, image_paths, transform=None, should_invert=True):
        self.image_paths = image_paths
        self.transform = transform
        self.should_invert = should_invert

    def __getitem__(self, index):
        img0_path, img0_label = random.choice(self.image_paths)
        should_get_same_class = random.randint(0, 1)

        if should_get_same_class:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] == img0_label])
        else:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] != img0_label])

        img0 = Image.open(img0_path).convert("L")
        img1 = Image.open(img1_path).convert("L")

        if self.should_invert:
            img0 = PIL.ImageOps.invert(img0)
            img1 = PIL.ImageOps.invert(img1)

        if self.transform:
            img0 = self.transform(img0)
            img1 = self.transform(img1)

        return img0, img1, torch.from_numpy(np.array([int(img1_label != img0_label)], dtype=np.float32))

    def __len__(self):
        return len(self.image_paths)

# Load dataset and create subsets
def load_dataset(directory, subset_size):
    folder_dataset = dset.ImageFolder(root=directory)
    subset_indices = random.sample(range(len(folder_dataset.imgs)), subset_size)
    subset_paths = [folder_dataset.imgs[i] for i in subset_indices]
    return SiameseNetworkDataset(image_paths=subset_paths, transform=transform, should_invert=False)

siamese_dataset_train = load_dataset(Config.training_dir, Config.train_subset_size)
train_dataloader = DataLoader(siamese_dataset_train, shuffle=True, num_workers=4, batch_size=Config.train_batch_size)

# Define Siamese Network
class SiameseNetwork(nn.Module):
    def __init__(self):
        super(SiameseNetwork, self).__init__()
        self.cnn1 = nn.Sequential(
            nn.ReflectionPad2d(1), nn.Conv2d(1, 4, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(4),
            nn.ReflectionPad2d(1), nn.Conv2d(4, 8, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(8),
            nn.ReflectionPad2d(1), nn.Conv2d(8, 8, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(8)
        )
        self.fc1 = nn.Sequential(
            nn.Linear(8 * 100 * 100, 500), nn.ReLU(inplace=True),
            nn.Linear(500, 500), nn.ReLU(inplace=True),
            nn.Linear(500, 128)  # Embedding dimension
        )

    def forward_once(self, x):
        output = self.cnn1(x)
        output = output.view(output.size()[0], -1)
        output = self.fc1(output)
        return output

    def forward(self, input1, input2):
        output1 = self.forward_once(input1)
        output2 = self.forward_once(input2)
        return output1, output2

# Contrastive Loss
class ContrastiveLoss(torch.nn.Module):
    def __init__(self, margin=2.0):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin

    def forward(self, output1, output2, label):
        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)
        loss_contrastive = torch.mean(
            (1 - label) * torch.pow(euclidean_distance, 2) +
            label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)
        )
        return loss_contrastive
# Modify train_model to track losses
def train_model(net, train_loader, val_loader, criterion, optimizer, epochs):
    train_losses = []
    val_losses = []
    val_accuracies = []
    best_loss = float('inf')
    trigger_times = 0

    for epoch in range(epochs):
        net.train()
        epoch_loss = 0
        for i, data in enumerate(train_loader, 0):
            img0, img1, label = data
            img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()
            optimizer.zero_grad()
            output1, output2 = net(img0, img1)
            loss_contrastive = criterion(output1, output2, label)
            loss_contrastive.backward()
            optimizer.step()
            epoch_loss += loss_contrastive.item()

        train_losses.append(epoch_loss / len(train_loader))
        val_loss, val_acc = validate_model(net, val_loader, criterion)
        val_losses.append(val_loss)
        val_accuracies.append(val_acc)

        print(f"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accuracies[-1]:.2f}%")
        # Early stopping
        if epoch_loss < best_loss:
            best_loss = epoch_loss
            trigger_times = 0
        else:
            trigger_times += 1
            if trigger_times >= Config.patience:
                print("Early stopping triggered")
                break
    plot_metrics(train_losses, val_losses, val_accuracies)

# Modify validate_model to return loss and accuracy
def validate_model(net, val_loader, criterion):
    net.eval()
    val_loss = 0
    correct, total = 0, 0

    with torch.no_grad():
        for data in val_loader:
            x0, x1, label = data
            x0, x1, label = x0.cuda(), x1.cuda(), label.cuda()
            output1, output2 = net(x0, x1)
            loss_contrastive = criterion(output1, output2, label)
            val_loss += loss_contrastive.item()

            euclidean_distance = F.pairwise_distance(output1, output2)
            prediction = (euclidean_distance > 1.0).float()
            correct += (prediction.cpu() == label.cpu()).sum().item()
            total += label.size(0)

    accuracy = (correct / total) * 100
    return val_loss / len(val_loader), accuracy

# Function to plot training and validation metrics
def plot_metrics(train_losses, val_losses, val_accuracies):
    epochs = range(1, len(train_losses) + 1)

    plt.figure(figsize=(12, 5))

    # Plot Loss
    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_losses, label="Train Loss")
    plt.plot(epochs, val_losses, label="Val Loss")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.title("Training & Validation Loss")
    plt.legend()

    # Plot Accuracy
    plt.subplot(1, 2, 2)
    plt.plot(epochs, val_accuracies, label="Val Accuracy", color="green")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy (%)")
    plt.title("Validation Accuracy")
    plt.legend()

    plt.show()

# Train and validate model
train_model(net, train_dataloader, val_dataloader, criterion, optimizer, Config.train_number_epochs)

"""# Increased subset size for training and validation (1000 - 200)"""

import torchvision.datasets as dset
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import random
import os
from PIL import Image
import numpy as np
import torch
import PIL.ImageOps
import torch.nn as nn
from torch import optim
import torch.nn.functional as F
import matplotlib.pyplot as plt

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Config class with dataset paths
class Config:
    base_dir = "/root/.cache/kagglehub/datasets/hearfool/vggface2/versions/1"
    training_dir = os.path.join(base_dir, "train")
    validation_dir = os.path.join(base_dir, "val")
    train_batch_size = 64
    train_number_epochs = 100
    train_subset_size = 1000  # Increased subset size for training
    val_subset_size = 200    # Subset size for validation
    patience = 10            # Early stopping patience

# Data augmentation and preprocessing
transform = transforms.Compose([
    transforms.Resize((100, 100)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor()
])

# Dataset class
class SiameseNetworkDataset(Dataset):
    def __init__(self, image_paths, transform=None, should_invert=True):
        self.image_paths = image_paths
        self.transform = transform
        self.should_invert = should_invert

    def __getitem__(self, index):
        img0_path, img0_label = random.choice(self.image_paths)
        should_get_same_class = random.randint(0, 1)

        if should_get_same_class:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] == img0_label])
        else:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] != img0_label])

        img0 = Image.open(img0_path).convert("L")
        img1 = Image.open(img1_path).convert("L")

        if self.should_invert:
            img0 = PIL.ImageOps.invert(img0)
            img1 = PIL.ImageOps.invert(img1)

        if self.transform:
            img0 = self.transform(img0)
            img1 = self.transform(img1)

        return img0, img1, torch.from_numpy(np.array([int(img1_label != img0_label)], dtype=np.float32))

    def __len__(self):
        return len(self.image_paths)

# Load dataset and create subsets
def load_dataset(directory, subset_size):
    folder_dataset = dset.ImageFolder(root=directory)
    subset_indices = random.sample(range(len(folder_dataset.imgs)), subset_size)
    subset_paths = [folder_dataset.imgs[i] for i in subset_indices]
    return SiameseNetworkDataset(image_paths=subset_paths, transform=transform, should_invert=False)

siamese_dataset_train = load_dataset(Config.training_dir, Config.train_subset_size)
train_dataloader = DataLoader(siamese_dataset_train, shuffle=True, num_workers=4, batch_size=Config.train_batch_size)

# Define Siamese Network
class SiameseNetwork(nn.Module):
    def __init__(self):
        super(SiameseNetwork, self).__init__()
        self.cnn1 = nn.Sequential(
            nn.ReflectionPad2d(1), nn.Conv2d(1, 4, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(4),
            nn.ReflectionPad2d(1), nn.Conv2d(4, 8, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(8),
            nn.ReflectionPad2d(1), nn.Conv2d(8, 8, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(8)
        )
        self.fc1 = nn.Sequential(
            nn.Linear(8 * 100 * 100, 500), nn.ReLU(inplace=True),
            nn.Linear(500, 500), nn.ReLU(inplace=True),
            nn.Linear(500, 128)  # Embedding dimension
        )

    def forward_once(self, x):
        output = self.cnn1(x)
        output = output.view(output.size()[0], -1)
        output = self.fc1(output)
        return output

    def forward(self, input1, input2):
        output1 = self.forward_once(input1)
        output2 = self.forward_once(input2)
        return output1, output2

# Contrastive Loss
class ContrastiveLoss(torch.nn.Module):
    def __init__(self, margin=2.0):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin

    def forward(self, output1, output2, label):
        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)
        loss_contrastive = torch.mean(
            (1 - label) * torch.pow(euclidean_distance, 2) +
            label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)
        )
        return loss_contrastive
# Modify train_model to track losses
def train_model(net, train_loader, val_loader, criterion, optimizer, epochs):
    train_losses = []
    val_losses = []
    val_accuracies = []
    best_loss = float('inf')
    trigger_times = 0

    for epoch in range(epochs):
        net.train()
        epoch_loss = 0
        for i, data in enumerate(train_loader, 0):
            img0, img1, label = data
            img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()
            optimizer.zero_grad()
            output1, output2 = net(img0, img1)
            loss_contrastive = criterion(output1, output2, label)
            loss_contrastive.backward()
            optimizer.step()
            epoch_loss += loss_contrastive.item()

        train_losses.append(epoch_loss / len(train_loader))
        val_loss, val_acc = validate_model(net, val_loader, criterion)
        val_losses.append(val_loss)
        val_accuracies.append(val_acc)

        print(f"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accuracies[-1]:.2f}%")
        # Early stopping
        if epoch_loss < best_loss:
            best_loss = epoch_loss
            trigger_times = 0
        else:
            trigger_times += 1
            if trigger_times >= Config.patience:
                print("Early stopping triggered")
                break
    plot_metrics(train_losses, val_losses, val_accuracies)

# Modify validate_model to return loss and accuracy
def validate_model(net, val_loader, criterion):
    net.eval()
    val_loss = 0
    correct, total = 0, 0

    with torch.no_grad():
        for data in val_loader:
            x0, x1, label = data
            x0, x1, label = x0.cuda(), x1.cuda(), label.cuda()
            output1, output2 = net(x0, x1)
            loss_contrastive = criterion(output1, output2, label)
            val_loss += loss_contrastive.item()

            euclidean_distance = F.pairwise_distance(output1, output2)
            prediction = (euclidean_distance > 1.0).float()
            correct += (prediction.cpu() == label.cpu()).sum().item()
            total += label.size(0)

    accuracy = (correct / total) * 100
    return val_loss / len(val_loader), accuracy

# Function to plot training and validation metrics
def plot_metrics(train_losses, val_losses, val_accuracies):
    epochs = range(1, len(train_losses) + 1)

    plt.figure(figsize=(12, 5))

    # Plot Loss
    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_losses, label="Train Loss")
    plt.plot(epochs, val_losses, label="Val Loss")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.title("Training & Validation Loss")
    plt.legend()

    # Plot Accuracy
    plt.subplot(1, 2, 2)
    plt.plot(epochs, val_accuracies, label="Val Accuracy", color="green")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy (%)")
    plt.title("Validation Accuracy")
    plt.legend()

    plt.show()

# Train and validate model
train_model(net, train_dataloader, val_dataloader, criterion, optimizer, Config.train_number_epochs)

"""# Increased subset size for training and validation (2000 - 500)"""

import torchvision.datasets as dset
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import random
import os
from PIL import Image
import numpy as np
import torch
import PIL.ImageOps
import torch.nn as nn
from torch import optim
import torch.nn.functional as F
import matplotlib.pyplot as plt

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Config class with dataset paths
class Config:
    base_dir = "/root/.cache/kagglehub/datasets/hearfool/vggface2/versions/1"
    training_dir = os.path.join(base_dir, "train")
    validation_dir = os.path.join(base_dir, "val")
    train_batch_size = 64
    train_number_epochs = 100
    train_subset_size = 2000  # Increased subset size for training
    val_subset_size = 500    # Subset size for validation
    patience = 10            # Early stopping patience

# Data augmentation and preprocessing
transform = transforms.Compose([
    transforms.Resize((100, 100)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor()
])

# Dataset class
class SiameseNetworkDataset(Dataset):
    def __init__(self, image_paths, transform=None, should_invert=True):
        self.image_paths = image_paths
        self.transform = transform
        self.should_invert = should_invert

    def __getitem__(self, index):
        img0_path, img0_label = random.choice(self.image_paths)
        should_get_same_class = random.randint(0, 1)

        if should_get_same_class:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] == img0_label])
        else:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] != img0_label])

        img0 = Image.open(img0_path).convert("L")
        img1 = Image.open(img1_path).convert("L")

        if self.should_invert:
            img0 = PIL.ImageOps.invert(img0)
            img1 = PIL.ImageOps.invert(img1)

        if self.transform:
            img0 = self.transform(img0)
            img1 = self.transform(img1)

        return img0, img1, torch.from_numpy(np.array([int(img1_label != img0_label)], dtype=np.float32))

    def __len__(self):
        return len(self.image_paths)

# Load dataset and create subsets
def load_dataset(directory, subset_size):
    folder_dataset = dset.ImageFolder(root=directory)
    subset_indices = random.sample(range(len(folder_dataset.imgs)), subset_size)
    subset_paths = [folder_dataset.imgs[i] for i in subset_indices]
    return SiameseNetworkDataset(image_paths=subset_paths, transform=transform, should_invert=False)

siamese_dataset_train = load_dataset(Config.training_dir, Config.train_subset_size)
train_dataloader = DataLoader(siamese_dataset_train, shuffle=True, num_workers=4, batch_size=Config.train_batch_size)

# Define Siamese Network
class SiameseNetwork(nn.Module):
    def __init__(self):
        super(SiameseNetwork, self).__init__()
        self.cnn1 = nn.Sequential(
            nn.ReflectionPad2d(1), nn.Conv2d(1, 4, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(4),
            nn.ReflectionPad2d(1), nn.Conv2d(4, 8, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(8),
            nn.ReflectionPad2d(1), nn.Conv2d(8, 8, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(8)
        )
        self.fc1 = nn.Sequential(
            nn.Linear(8 * 100 * 100, 500), nn.ReLU(inplace=True),
            nn.Linear(500, 500), nn.ReLU(inplace=True),
            nn.Linear(500, 128)  # Embedding dimension
        )

    def forward_once(self, x):
        output = self.cnn1(x)
        output = output.view(output.size()[0], -1)
        output = self.fc1(output)
        return output

    def forward(self, input1, input2):
        output1 = self.forward_once(input1)
        output2 = self.forward_once(input2)
        return output1, output2

# Contrastive Loss
class ContrastiveLoss(torch.nn.Module):
    def __init__(self, margin=2.0):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin

    def forward(self, output1, output2, label):
        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)
        loss_contrastive = torch.mean(
            (1 - label) * torch.pow(euclidean_distance, 2) +
            label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)
        )
        return loss_contrastive
# Modify train_model to track losses
def train_model(net, train_loader, val_loader, criterion, optimizer, epochs):
    train_losses = []
    val_losses = []
    val_accuracies = []
    best_loss = float('inf')
    trigger_times = 0

    for epoch in range(epochs):
        net.train()
        epoch_loss = 0
        for i, data in enumerate(train_loader, 0):
            img0, img1, label = data
            img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()
            optimizer.zero_grad()
            output1, output2 = net(img0, img1)
            loss_contrastive = criterion(output1, output2, label)
            loss_contrastive.backward()
            optimizer.step()
            epoch_loss += loss_contrastive.item()

        train_losses.append(epoch_loss / len(train_loader))
        val_loss, val_acc = validate_model(net, val_loader, criterion)
        val_losses.append(val_loss)
        val_accuracies.append(val_acc)

        print(f"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accuracies[-1]:.2f}%")
        # Early stopping
        if epoch_loss < best_loss:
            best_loss = epoch_loss
            trigger_times = 0
        else:
            trigger_times += 1
            if trigger_times >= Config.patience:
                print("Early stopping triggered")
                break
    plot_metrics(train_losses, val_losses, val_accuracies)

# Modify validate_model to return loss and accuracy
def validate_model(net, val_loader, criterion):
    net.eval()
    val_loss = 0
    correct, total = 0, 0

    with torch.no_grad():
        for data in val_loader:
            x0, x1, label = data
            x0, x1, label = x0.cuda(), x1.cuda(), label.cuda()
            output1, output2 = net(x0, x1)
            loss_contrastive = criterion(output1, output2, label)
            val_loss += loss_contrastive.item()

            euclidean_distance = F.pairwise_distance(output1, output2)
            prediction = (euclidean_distance > 1.0).float()
            correct += (prediction.cpu() == label.cpu()).sum().item()
            total += label.size(0)

    accuracy = (correct / total) * 100
    return val_loss / len(val_loader), accuracy

# Function to plot training and validation metrics
def plot_metrics(train_losses, val_losses, val_accuracies):
    epochs = range(1, len(train_losses) + 1)

    plt.figure(figsize=(12, 5))

    # Plot Loss
    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_losses, label="Train Loss")
    plt.plot(epochs, val_losses, label="Val Loss")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.title("Training & Validation Loss")
    plt.legend()

    # Plot Accuracy
    plt.subplot(1, 2, 2)
    plt.plot(epochs, val_accuracies, label="Val Accuracy", color="green")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy (%)")
    plt.title("Validation Accuracy")
    plt.legend()

    plt.show()

# Train and validate model
train_model(net, train_dataloader, val_dataloader, criterion, optimizer, Config.train_number_epochs)

import torchvision.datasets as dset
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import random
import os
from PIL import Image
import numpy as np
import torch
import PIL.ImageOps
import torch.nn as nn
from torch import optim
import torch.nn.functional as F
import matplotlib.pyplot as plt

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Config class with dataset paths
class Config:
    base_dir = "/root/.cache/kagglehub/datasets/hearfool/vggface2/versions/1"
    training_dir = os.path.join(base_dir, "train")
    validation_dir = os.path.join(base_dir, "val")
    train_batch_size = 64
    train_number_epochs = 100
    train_subset_size = 500  # Increased subset size for training
    val_subset_size = 100    # Subset size for validation
    patience = 10            # Early stopping patience

# Data augmentation and preprocessing
transform = transforms.Compose([
    transforms.Resize((100, 100)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor()
])

# Dataset class
class SiameseNetworkDataset(Dataset):
    def __init__(self, image_paths, transform=None, should_invert=True):
        self.image_paths = image_paths
        self.transform = transform
        self.should_invert = should_invert

    def __getitem__(self, index):
        img0_path, img0_label = random.choice(self.image_paths)
        should_get_same_class = random.randint(0, 1)

        if should_get_same_class:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] == img0_label])
        else:
            img1_path, img1_label = random.choice([img for img in self.image_paths if img[1] != img0_label])

        img0 = Image.open(img0_path).convert("L")
        img1 = Image.open(img1_path).convert("L")

        if self.should_invert:
            img0 = PIL.ImageOps.invert(img0)
            img1 = PIL.ImageOps.invert(img1)

        if self.transform:
            img0 = self.transform(img0)
            img1 = self.transform(img1)

        return img0, img1, torch.from_numpy(np.array([int(img1_label != img0_label)], dtype=np.float32))

    def __len__(self):
        return len(self.image_paths)

# Load dataset and create subsets
def load_dataset(directory, subset_size):
    folder_dataset = dset.ImageFolder(root=directory)
    subset_indices = random.sample(range(len(folder_dataset.imgs)), subset_size)
    subset_paths = [folder_dataset.imgs[i] for i in subset_indices]
    return SiameseNetworkDataset(image_paths=subset_paths, transform=transform, should_invert=False)

siamese_dataset_train = load_dataset(Config.training_dir, Config.train_subset_size)
train_dataloader = DataLoader(siamese_dataset_train, shuffle=True, num_workers=4, batch_size=Config.train_batch_size)

# Define Siamese Network
class SiameseNetwork(nn.Module):
    def __init__(self):
        super(SiameseNetwork, self).__init__()
        self.cnn1 = nn.Sequential(
            nn.ReflectionPad2d(1), nn.Conv2d(1, 4, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(4),
            nn.ReflectionPad2d(1), nn.Conv2d(4, 8, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(8),
            nn.ReflectionPad2d(1), nn.Conv2d(8, 8, kernel_size=3), nn.ReLU(inplace=True), nn.BatchNorm2d(8)
        )
        self.fc1 = nn.Sequential(
            nn.Linear(8 * 100 * 100, 500), nn.ReLU(inplace=True),
            nn.Linear(500, 500), nn.ReLU(inplace=True),
            nn.Linear(500, 128)  # Embedding dimension
        )

    def forward_once(self, x):
        output = self.cnn1(x)
        output = output.view(output.size()[0], -1)
        output = self.fc1(output)
        return output

    def forward(self, input1, input2):
        output1 = self.forward_once(input1)
        output2 = self.forward_once(input2)
        return output1, output2

# Contrastive Loss
class ContrastiveLoss(torch.nn.Module):
    def __init__(self, margin=2.0):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin

    def forward(self, output1, output2, label):
        euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)
        loss_contrastive = torch.mean(
            (1 - label) * torch.pow(euclidean_distance, 2) +
            label * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)
        )
        return loss_contrastive
# Modify train_model to track losses
def train_model(net, train_loader, val_loader, criterion, optimizer, epochs):
    train_losses = []
    val_losses = []
    val_accuracies = []
    best_loss = float('inf')
    trigger_times = 0

    for epoch in range(epochs):
        net.train()
        epoch_loss = 0
        for i, data in enumerate(train_loader, 0):
            img0, img1, label = data
            img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()
            optimizer.zero_grad()
            output1, output2 = net(img0, img1)
            loss_contrastive = criterion(output1, output2, label)
            loss_contrastive.backward()
            optimizer.step()
            epoch_loss += loss_contrastive.item()

        train_losses.append(epoch_loss / len(train_loader))
        val_loss, val_acc = validate_model(net, val_loader, criterion)
        val_losses.append(val_loss)
        val_accuracies.append(val_acc)

        print(f"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accuracies[-1]:.2f}%")
        # Early stopping
        if epoch_loss < best_loss:
            best_loss = epoch_loss
            trigger_times = 0
        else:
            trigger_times += 1
            if trigger_times >= Config.patience:
                print("Early stopping triggered")
                break
    plot_metrics(train_losses, val_losses, val_accuracies)

# Modify validate_model to return loss and accuracy
def validate_model(net, val_loader, criterion):
    net.eval()
    val_loss = 0
    correct, total = 0, 0

    with torch.no_grad():
        for data in val_loader:
            x0, x1, label = data
            x0, x1, label = x0.cuda(), x1.cuda(), label.cuda()
            output1, output2 = net(x0, x1)
            loss_contrastive = criterion(output1, output2, label)
            val_loss += loss_contrastive.item()

            euclidean_distance = F.pairwise_distance(output1, output2)
            prediction = (euclidean_distance > 1.0).float()
            correct += (prediction.cpu() == label.cpu()).sum().item()
            total += label.size(0)

    accuracy = (correct / total) * 100
    return val_loss / len(val_loader), accuracy

# Function to plot training and validation metrics
def plot_metrics(train_losses, val_losses, val_accuracies):
    epochs = range(1, len(train_losses) + 1)

    plt.figure(figsize=(12, 5))

    # Plot Loss
    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_losses, label="Train Loss")
    plt.plot(epochs, val_losses, label="Val Loss")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.title("Training & Validation Loss")
    plt.legend()

    # Plot Accuracy
    plt.subplot(1, 2, 2)
    plt.plot(epochs, val_accuracies, label="Val Accuracy", color="green")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy (%)")
    plt.title("Validation Accuracy")
    plt.legend()

    plt.show()

# Train and validate model
train_model(net, train_dataloader, val_dataloader, criterion, optimizer, Config.train_number_epochs)

torch.save(net.state_dict(), "siamese_model.pth")

from google.colab import files
files.download('siamese_model.pth')